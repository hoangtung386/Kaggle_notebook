{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 52254,
          "databundleVersionId": 9674523,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Segment_train_RSNA",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangtung386/Kaggle_notebook/blob/main/Segment_train_RSNA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "IJyWN4nKNQmc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "rsna_2023_abdominal_trauma_detection_path = kagglehub.competition_download('rsna-2023-abdominal-trauma-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "AE-5v_-6NQmn"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "bBbL0HVdNQmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q monai wandb nibabel torchsummary"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:52:28.733159Z",
          "iopub.execute_input": "2025-10-25T08:52:28.733784Z",
          "iopub.status.idle": "2025-10-25T08:53:54.943655Z",
          "shell.execute_reply.started": "2025-10-25T08:52:28.733756Z",
          "shell.execute_reply": "2025-10-25T08:53:54.942487Z"
        },
        "id": "Irgp3qObNQmv",
        "outputId": "193934f2-1d1d-412c-dfcf-d734d3a72621"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from monai.transforms import (Compose, LoadImaged, EnsureChannelFirstd, Spacingd, ScaleIntensityRanged,\n",
        "                              Orientationd, CropForegroundd, SpatialPadd, RandCropByPosNegLabeld,\n",
        "                              RandAffined, ToTensord, RandSpatialCropd, ResizeWithPadOrCropd)\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss\n",
        "from monai.data import CacheDataset, list_data_collate\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.utils import set_determinism\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "import wandb\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:53:54.945675Z",
          "iopub.execute_input": "2025-10-25T08:53:54.946122Z",
          "iopub.status.idle": "2025-10-25T08:54:40.758353Z",
          "shell.execute_reply.started": "2025-10-25T08:53:54.946093Z",
          "shell.execute_reply": "2025-10-25T08:54:40.75743Z"
        },
        "id": "oJ5GRBnWNQmy",
        "outputId": "60f20d47-8e8b-409e-8923-e60192424e94"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-10-25 08:54:19.623377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761382459.848325      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761382459.914859      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W&B Authentication"
      ],
      "metadata": {
        "id": "eARUFim_NQm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "user_secrets = UserSecretsClient()\n",
        "use_wandb = True  # Đặt thành False nếu không muốn dùng wandb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:40.759309Z",
          "iopub.execute_input": "2025-10-25T08:54:40.759662Z",
          "iopub.status.idle": "2025-10-25T08:54:40.775899Z",
          "shell.execute_reply.started": "2025-10-25T08:54:40.759632Z",
          "shell.execute_reply": "2025-10-25T08:54:40.775051Z"
        },
        "id": "__B27IKzNQm3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if use_wandb:\n",
        "    try:\n",
        "        wandb_api = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
        "        wandb.login(key=wandb_api)\n",
        "        print(\"W&B authentication successful!\")\n",
        "    except Exception as e:\n",
        "        print(f\"W&B authentication failed: {e}\")\n",
        "        print(\"Continuing without W&B logging\")\n",
        "        use_wandb = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:40.777658Z",
          "iopub.execute_input": "2025-10-25T08:54:40.777985Z",
          "iopub.status.idle": "2025-10-25T08:54:47.478106Z",
          "shell.execute_reply.started": "2025-10-25T08:54:40.77796Z",
          "shell.execute_reply": "2025-10-25T08:54:47.477119Z"
        },
        "id": "d61979e1NQm6",
        "outputId": "4694545c-01b8-4aea-e3e2-940be84ece9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoangtung386\u001b[0m (\u001b[33mlevuhoangtung\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "W&B authentication successful!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed\n",
        "random_seed = 42\n",
        "set_determinism(seed=random_seed)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.479055Z",
          "iopub.execute_input": "2025-10-25T08:54:47.480072Z",
          "iopub.status.idle": "2025-10-25T08:54:47.491029Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.480046Z",
          "shell.execute_reply": "2025-10-25T08:54:47.490049Z"
        },
        "id": "uKLZmQRiNQm8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.491721Z",
          "iopub.execute_input": "2025-10-25T08:54:47.492058Z",
          "iopub.status.idle": "2025-10-25T08:54:47.504866Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.492031Z",
          "shell.execute_reply": "2025-10-25T08:54:47.504083Z"
        },
        "id": "4HjHE9iYNQm-",
        "outputId": "e3b22852-e10f-493b-a2cd-0d4af0634fd2"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cpu')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I . Data preprocessing"
      ],
      "metadata": {
        "id": "QZen1LtoNQm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Paths và Config"
      ],
      "metadata": {
        "id": "8EejB6DbNQnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/kaggle/input/rsna-2023-abdominal-trauma-detection/'\n",
        "output_dir = '/kaggle/working'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "CONFIG = {\n",
        "    'seed': random_seed,\n",
        "    'train_split': 0.8,\n",
        "    'batch_size': 1,\n",
        "    'num_epochs': 20,\n",
        "    'learning_rate': 1e-3,\n",
        "    'spatial_size': (96, 96, 96),\n",
        "    'init_features': 16,\n",
        "    'num_classes': 6,\n",
        "    'cache_rate': 0,\n",
        "    'num_workers': 2,\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.505801Z",
          "iopub.execute_input": "2025-10-25T08:54:47.506156Z",
          "iopub.status.idle": "2025-10-25T08:54:47.53629Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.506128Z",
          "shell.execute_reply": "2025-10-25T08:54:47.535157Z"
        },
        "id": "_KGPB7uqNQnD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Data"
      ],
      "metadata": {
        "id": "AUyrv8eXNQnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_meta = pd.read_csv(os.path.join(base_path, 'train_series_meta.csv'))\n",
        "labels = pd.read_csv(os.path.join(base_path, 'train_2024.csv'))\n",
        "\n",
        "seg_path = os.path.join(base_path, 'segmentations')\n",
        "seg_files = [f for f in os.listdir(seg_path) if f.endswith('.nii')]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.53745Z",
          "iopub.execute_input": "2025-10-25T08:54:47.537786Z",
          "iopub.status.idle": "2025-10-25T08:54:47.619534Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.537758Z",
          "shell.execute_reply": "2025-10-25T08:54:47.618487Z"
        },
        "id": "uWgis7RcNQnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for seg in seg_files:\n",
        "    series_id = int(seg.split('.')[0])\n",
        "    patient_row = series_meta[series_meta['series_id'] == series_id]\n",
        "    if not patient_row.empty:\n",
        "        patient_id = int(patient_row['patient_id'].values[0])\n",
        "        image_dir = os.path.join(base_path, f'train_images/{patient_id}/{series_id}')\n",
        "        seg_file = os.path.join(seg_path, seg)\n",
        "        data_list.append({\n",
        "            'image': image_dir,\n",
        "            'seg': seg_file\n",
        "        })"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.620481Z",
          "iopub.execute_input": "2025-10-25T08:54:47.620737Z",
          "iopub.status.idle": "2025-10-25T08:54:47.709458Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.620719Z",
          "shell.execute_reply": "2025-10-25T08:54:47.708398Z"
        },
        "id": "e3q3PPR6NQna"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_list, val_list = train_test_split(\n",
        "    data_list,\n",
        "    test_size=1-CONFIG['train_split'],\n",
        "    random_state=CONFIG['seed'],\n",
        "    shuffle=True\n",
        ")\n",
        "print(f\"Train samples: {len(train_list)}, Val samples: {len(val_list)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.713028Z",
          "iopub.execute_input": "2025-10-25T08:54:47.713352Z",
          "iopub.status.idle": "2025-10-25T08:54:47.719857Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.713329Z",
          "shell.execute_reply": "2025-10-25T08:54:47.71907Z"
        },
        "id": "vhnh26CbNQna",
        "outputId": "1c648822-7d0a-4562-ac7e-31f834f73ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train samples: 164, Val samples: 42\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transforms"
      ],
      "metadata": {
        "id": "tpaVdONZNQnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose([\n",
        "    LoadImaged(keys=['image', 'seg']),\n",
        "    EnsureChannelFirstd(keys=['image', 'seg']),\n",
        "    Orientationd(keys=['image', 'seg'], axcodes='RAS'),\n",
        "    Spacingd(keys=['image', 'seg'], pixdim=(1.0, 1.0, 1.0), mode=('bilinear', 'nearest')),\n",
        "    ScaleIntensityRanged(keys=['image'], a_min=-125, a_max=275, b_min=0.0, b_max=1.0, clip=True),\n",
        "    CropForegroundd(keys=['image', 'seg'], source_key='image'),\n",
        "    SpatialPadd(keys=['image', 'seg'], spatial_size=CONFIG['spatial_size']),\n",
        "    RandCropByPosNegLabeld(keys=['image', 'seg'], label_key='seg',\n",
        "                           spatial_size=CONFIG['spatial_size'],\n",
        "                           pos=1.0, neg=1.0, num_samples=2),\n",
        "    RandAffined(keys=['image', 'seg'], prob=0.2, rotate_range=0.1,\n",
        "                scale_range=0.1, mode=('bilinear', 'nearest')),\n",
        "    ToTensord(keys=['image', 'seg'])\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.72072Z",
          "iopub.execute_input": "2025-10-25T08:54:47.721086Z",
          "iopub.status.idle": "2025-10-25T08:54:47.746038Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.721059Z",
          "shell.execute_reply": "2025-10-25T08:54:47.74509Z"
        },
        "id": "XbtnH8pLNQnb",
        "outputId": "b782cc86-c544-4856-c453-d6bff7297e92"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n  warn_deprecated(argname, msg, warning_category)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_transforms = Compose([\n",
        "    LoadImaged(keys=['image', 'seg']),\n",
        "    EnsureChannelFirstd(keys=['image', 'seg']),\n",
        "    Orientationd(keys=['image', 'seg'], axcodes='RAS'),\n",
        "    Spacingd(keys=['image', 'seg'], pixdim=(1.0, 1.0, 1.0), mode=('bilinear', 'nearest')),\n",
        "    ScaleIntensityRanged(keys=['image'], a_min=-125, a_max=275, b_min=0.0, b_max=1.0, clip=True),\n",
        "    CropForegroundd(keys=['image', 'seg'], source_key='image'),\n",
        "    SpatialPadd(keys=['image', 'seg'], spatial_size=CONFIG['spatial_size']),\n",
        "    ToTensord(keys=['image', 'seg'])\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.747022Z",
          "iopub.execute_input": "2025-10-25T08:54:47.747354Z",
          "iopub.status.idle": "2025-10-25T08:54:47.755506Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.747331Z",
          "shell.execute_reply": "2025-10-25T08:54:47.754565Z"
        },
        "id": "hs_NhJOcNQnc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data processing"
      ],
      "metadata": {
        "id": "De-9LADtNQnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RSNADataset(CacheDataset):\n",
        "    def __init__(self, data, transforms, cache_rate=1.0):\n",
        "        super().__init__(data, transforms, cache_num=len(data), cache_rate=cache_rate)\n",
        "\n",
        "train_ds = RSNADataset(train_list, train_transforms, cache_rate=CONFIG['cache_rate'])\n",
        "val_ds = RSNADataset(val_list, val_transforms, cache_rate=CONFIG['cache_rate'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.756547Z",
          "iopub.execute_input": "2025-10-25T08:54:47.756887Z",
          "iopub.status.idle": "2025-10-25T08:54:47.768938Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.756858Z",
          "shell.execute_reply": "2025-10-25T08:54:47.767842Z"
        },
        "id": "Zo6TfK_5NQne"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. DataLoader"
      ],
      "metadata": {
        "id": "eFZbYWewNQne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True,\n",
        "                          num_workers=CONFIG['num_workers'], collate_fn=list_data_collate,\n",
        "                          persistent_workers=False, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False,\n",
        "                        num_workers=CONFIG['num_workers'],\n",
        "                        persistent_workers=False, pin_memory=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.770027Z",
          "iopub.execute_input": "2025-10-25T08:54:47.770295Z",
          "iopub.status.idle": "2025-10-25T08:54:47.784047Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.770274Z",
          "shell.execute_reply": "2025-10-25T08:54:47.782975Z"
        },
        "id": "n4oJyWlyNQnf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Unet 3D Architecture"
      ],
      "metadata": {
        "id": "OSabt3cTNQng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Initialize the architecture"
      ],
      "metadata": {
        "id": "CWyr0jKxNQng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.785109Z",
          "iopub.execute_input": "2025-10-25T08:54:47.786106Z",
          "iopub.status.idle": "2025-10-25T08:54:47.804363Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.78608Z",
          "shell.execute_reply": "2025-10-25T08:54:47.803415Z"
        },
        "id": "BE55SwQYNQng"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool3d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.805312Z",
          "iopub.execute_input": "2025-10-25T08:54:47.805583Z",
          "iopub.status.idle": "2025-10-25T08:54:47.82052Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.805559Z",
          "shell.execute_reply": "2025-10-25T08:54:47.819674Z"
        },
        "id": "O9ws8-TiNQng"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.821445Z",
          "iopub.execute_input": "2025-10-25T08:54:47.82172Z",
          "iopub.status.idle": "2025-10-25T08:54:47.837362Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.821695Z",
          "shell.execute_reply": "2025-10-25T08:54:47.83632Z"
        },
        "id": "JRpQpT4mNQnh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=6, init_features=16):\n",
        "        super().__init__()\n",
        "        features = init_features\n",
        "\n",
        "        self.inc = DoubleConv(in_channels, features)\n",
        "        self.down1 = Down(features, features * 2)\n",
        "        self.down2 = Down(features * 2, features * 4)\n",
        "        self.down3 = Down(features * 4, features * 8)\n",
        "        self.down4 = Down(features * 8, features * 16)\n",
        "\n",
        "        self.up1 = Up(features * 16, features * 8)\n",
        "        self.up2 = Up(features * 8, features * 4)\n",
        "        self.up3 = Up(features * 4, features * 2)\n",
        "        self.up4 = Up(features * 2, features)\n",
        "\n",
        "        self.outc = nn.Conv3d(features, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.838412Z",
          "iopub.execute_input": "2025-10-25T08:54:47.838759Z",
          "iopub.status.idle": "2025-10-25T08:54:47.856972Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.838727Z",
          "shell.execute_reply": "2025-10-25T08:54:47.856177Z"
        },
        "id": "psams5k7NQni"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Initialize model"
      ],
      "metadata": {
        "id": "OuUVYc6LNQni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = UNet3D(\n",
        "    in_channels=1,\n",
        "    out_channels=CONFIG['num_classes'],\n",
        "    init_features=CONFIG['init_features']\n",
        ").to(device)\n",
        "\n",
        "summary(model, (1, 96, 96, 96))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:47.858284Z",
          "iopub.execute_input": "2025-10-25T08:54:47.858539Z",
          "iopub.status.idle": "2025-10-25T08:54:52.232726Z",
          "shell.execute_reply.started": "2025-10-25T08:54:47.858518Z",
          "shell.execute_reply": "2025-10-25T08:54:52.231771Z"
        },
        "id": "Y6vz4t_JNQnk",
        "outputId": "c697651a-ef72-40e7-b626-7fce04d36ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv3d-1       [-1, 16, 96, 96, 96]             448\n       BatchNorm3d-2       [-1, 16, 96, 96, 96]              32\n              ReLU-3       [-1, 16, 96, 96, 96]               0\n            Conv3d-4       [-1, 16, 96, 96, 96]           6,928\n       BatchNorm3d-5       [-1, 16, 96, 96, 96]              32\n              ReLU-6       [-1, 16, 96, 96, 96]               0\n        DoubleConv-7       [-1, 16, 96, 96, 96]               0\n         MaxPool3d-8       [-1, 16, 48, 48, 48]               0\n            Conv3d-9       [-1, 32, 48, 48, 48]          13,856\n      BatchNorm3d-10       [-1, 32, 48, 48, 48]              64\n             ReLU-11       [-1, 32, 48, 48, 48]               0\n           Conv3d-12       [-1, 32, 48, 48, 48]          27,680\n      BatchNorm3d-13       [-1, 32, 48, 48, 48]              64\n             ReLU-14       [-1, 32, 48, 48, 48]               0\n       DoubleConv-15       [-1, 32, 48, 48, 48]               0\n             Down-16       [-1, 32, 48, 48, 48]               0\n        MaxPool3d-17       [-1, 32, 24, 24, 24]               0\n           Conv3d-18       [-1, 64, 24, 24, 24]          55,360\n      BatchNorm3d-19       [-1, 64, 24, 24, 24]             128\n             ReLU-20       [-1, 64, 24, 24, 24]               0\n           Conv3d-21       [-1, 64, 24, 24, 24]         110,656\n      BatchNorm3d-22       [-1, 64, 24, 24, 24]             128\n             ReLU-23       [-1, 64, 24, 24, 24]               0\n       DoubleConv-24       [-1, 64, 24, 24, 24]               0\n             Down-25       [-1, 64, 24, 24, 24]               0\n        MaxPool3d-26       [-1, 64, 12, 12, 12]               0\n           Conv3d-27      [-1, 128, 12, 12, 12]         221,312\n      BatchNorm3d-28      [-1, 128, 12, 12, 12]             256\n             ReLU-29      [-1, 128, 12, 12, 12]               0\n           Conv3d-30      [-1, 128, 12, 12, 12]         442,496\n      BatchNorm3d-31      [-1, 128, 12, 12, 12]             256\n             ReLU-32      [-1, 128, 12, 12, 12]               0\n       DoubleConv-33      [-1, 128, 12, 12, 12]               0\n             Down-34      [-1, 128, 12, 12, 12]               0\n        MaxPool3d-35         [-1, 128, 6, 6, 6]               0\n           Conv3d-36         [-1, 256, 6, 6, 6]         884,992\n      BatchNorm3d-37         [-1, 256, 6, 6, 6]             512\n             ReLU-38         [-1, 256, 6, 6, 6]               0\n           Conv3d-39         [-1, 256, 6, 6, 6]       1,769,728\n      BatchNorm3d-40         [-1, 256, 6, 6, 6]             512\n             ReLU-41         [-1, 256, 6, 6, 6]               0\n       DoubleConv-42         [-1, 256, 6, 6, 6]               0\n             Down-43         [-1, 256, 6, 6, 6]               0\n  ConvTranspose3d-44      [-1, 128, 12, 12, 12]         262,272\n           Conv3d-45      [-1, 128, 12, 12, 12]         884,864\n      BatchNorm3d-46      [-1, 128, 12, 12, 12]             256\n             ReLU-47      [-1, 128, 12, 12, 12]               0\n           Conv3d-48      [-1, 128, 12, 12, 12]         442,496\n      BatchNorm3d-49      [-1, 128, 12, 12, 12]             256\n             ReLU-50      [-1, 128, 12, 12, 12]               0\n       DoubleConv-51      [-1, 128, 12, 12, 12]               0\n               Up-52      [-1, 128, 12, 12, 12]               0\n  ConvTranspose3d-53       [-1, 64, 24, 24, 24]          65,600\n           Conv3d-54       [-1, 64, 24, 24, 24]         221,248\n      BatchNorm3d-55       [-1, 64, 24, 24, 24]             128\n             ReLU-56       [-1, 64, 24, 24, 24]               0\n           Conv3d-57       [-1, 64, 24, 24, 24]         110,656\n      BatchNorm3d-58       [-1, 64, 24, 24, 24]             128\n             ReLU-59       [-1, 64, 24, 24, 24]               0\n       DoubleConv-60       [-1, 64, 24, 24, 24]               0\n               Up-61       [-1, 64, 24, 24, 24]               0\n  ConvTranspose3d-62       [-1, 32, 48, 48, 48]          16,416\n           Conv3d-63       [-1, 32, 48, 48, 48]          55,328\n      BatchNorm3d-64       [-1, 32, 48, 48, 48]              64\n             ReLU-65       [-1, 32, 48, 48, 48]               0\n           Conv3d-66       [-1, 32, 48, 48, 48]          27,680\n      BatchNorm3d-67       [-1, 32, 48, 48, 48]              64\n             ReLU-68       [-1, 32, 48, 48, 48]               0\n       DoubleConv-69       [-1, 32, 48, 48, 48]               0\n               Up-70       [-1, 32, 48, 48, 48]               0\n  ConvTranspose3d-71       [-1, 16, 96, 96, 96]           4,112\n           Conv3d-72       [-1, 16, 96, 96, 96]          13,840\n      BatchNorm3d-73       [-1, 16, 96, 96, 96]              32\n             ReLU-74       [-1, 16, 96, 96, 96]               0\n           Conv3d-75       [-1, 16, 96, 96, 96]           6,928\n      BatchNorm3d-76       [-1, 16, 96, 96, 96]              32\n             ReLU-77       [-1, 16, 96, 96, 96]               0\n       DoubleConv-78       [-1, 16, 96, 96, 96]               0\n               Up-79       [-1, 16, 96, 96, 96]               0\n           Conv3d-80        [-1, 6, 96, 96, 96]             102\n================================================================\nTotal params: 5,647,942\nTrainable params: 5,647,942\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 3.38\nForward/backward pass size (MB): 2392.24\nParams size (MB): 21.55\nEstimated Total Size (MB): 2417.16\n----------------------------------------------------------------\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "nTZ-bZ51NQnl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Trainer Class"
      ],
      "metadata": {
        "id": "wcmD4ssWNQnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetTrainer:\n",
        "    def __init__(self, model, train_loader, val_loader, config, device,\n",
        "                 checkpoint_dir='/kaggle/working', use_wandb=True):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.config = config\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.use_wandb = use_wandb\n",
        "\n",
        "        self.device = device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Loss and optimizer\n",
        "        self.criterion = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='max', patience=5, factor=0.5, verbose=True\n",
        "        )\n",
        "        self.dice_metric = DiceMetric(include_background=False, reduction='mean')\n",
        "\n",
        "        # Training state\n",
        "        self.start_epoch = 0\n",
        "        self.best_dice = 0.0\n",
        "        self.history = []\n",
        "        self.wandb_run_id = None\n",
        "\n",
        "        # Paths\n",
        "        self.checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pth')\n",
        "        self.best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "        self.history_csv_path = os.path.join(checkpoint_dir, 'training_history.csv')\n",
        "\n",
        "    def save_checkpoint(self, epoch, val_dice, is_best=False):\n",
        "        \"\"\"Save checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'best_dice': self.best_dice,\n",
        "            'history': self.history,\n",
        "            'config': self.config,\n",
        "            'wandb_run_id': self.wandb_run_id\n",
        "        }\n",
        "\n",
        "        # Save latest checkpoint\n",
        "        torch.save(checkpoint, self.checkpoint_path)\n",
        "        print(f\"Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "        # Save best model\n",
        "        if is_best:\n",
        "            torch.save(checkpoint, self.best_model_path)\n",
        "            print(f\"Best model saved! Dice: {val_dice:.4f}\")\n",
        "\n",
        "    def load_checkpoint(self):\n",
        "        \"\"\"Load checkpoint if exists\"\"\"\n",
        "        if os.path.exists(self.checkpoint_path):\n",
        "            print(f\"Loading checkpoint from {self.checkpoint_path}\")\n",
        "            checkpoint = torch.load(self.checkpoint_path, map_location=self.device)\n",
        "\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            self.start_epoch = checkpoint['epoch'] + 1\n",
        "            self.best_dice = checkpoint['best_dice']\n",
        "            self.history = checkpoint['history']\n",
        "\n",
        "            # Load wandb run ID if available\n",
        "            if 'wandb_run_id' in checkpoint:\n",
        "                self.wandb_run_id = checkpoint['wandb_run_id']\n",
        "\n",
        "            print(f\"Resumed from epoch {self.start_epoch}, best dice: {self.best_dice:.4f}\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def save_history_csv(self):\n",
        "        \"\"\"Save training history to CSV\"\"\"\n",
        "        if self.history:\n",
        "            df = pd.DataFrame(self.history)\n",
        "            df.to_csv(self.history_csv_path, index=False)\n",
        "            print(f\"History saved to {self.history_csv_path}\")\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        \"\"\"Train one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch} [Train]\")\n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(self.device)\n",
        "            segs = batch['seg'].to(self.device).long()\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, segs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_loss = total_loss / len(self.train_loader)\n",
        "        return avg_loss\n",
        "\n",
        "    def validate(self, epoch):\n",
        "        \"\"\"Validate\"\"\"\n",
        "        self.model.eval()\n",
        "        self.dice_metric.reset()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(self.val_loader, desc=f\"Epoch {epoch} [Val]\")\n",
        "            for batch in pbar:\n",
        "                images = batch['image'].to(self.device)\n",
        "                segs = batch['seg'].to(self.device)\n",
        "\n",
        "                outputs = sliding_window_inference(\n",
        "                    images, self.config['spatial_size'], 1, self.model, overlap=0.5\n",
        "                )\n",
        "                self.dice_metric(y_pred=outputs, y=segs)\n",
        "\n",
        "        val_dice = self.dice_metric.aggregate().item()\n",
        "        return val_dice\n",
        "\n",
        "    def train(self, num_epochs=None):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        if num_epochs is None:\n",
        "            num_epochs = self.config['num_epochs']\n",
        "\n",
        "        # Try to resume from checkpoint\n",
        "        resumed = self.load_checkpoint()\n",
        "\n",
        "        # Initialize wandb\n",
        "        if self.use_wandb:\n",
        "            if resumed and self.wandb_run_id:\n",
        "                # Resume existing wandb run\n",
        "                wandb.init(\n",
        "                    project=\"my-3D-Unet-segment-RSNA\",\n",
        "                    config=self.config,\n",
        "                    resume=\"allow\",\n",
        "                    id=self.wandb_run_id,\n",
        "                    name=f\"unet3d_resumed_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                )\n",
        "                print(f\"Resumed W&B run: {self.wandb_run_id}\")\n",
        "            else:\n",
        "                # Create new wandb run\n",
        "                run_name = f\"unet3d_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                wandb.init(\n",
        "                    project=\"my-3D-Unet-segment-RSNA\",\n",
        "                    config=self.config,\n",
        "                    name=run_name,\n",
        "                    tags=[\"3d-unet\", \"organ-segmentation\", \"rsna\"]\n",
        "                )\n",
        "                self.wandb_run_id = wandb.run.id\n",
        "                print(f\"Created new W&B run: {self.wandb_run_id}\")\n",
        "\n",
        "            # Watch model\n",
        "            wandb.watch(self.model, log='all', log_freq=100)\n",
        "\n",
        "        print(f\"\\nStarting training from epoch {self.start_epoch} to {num_epochs}\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()) / 1e6:.2f}M\")\n",
        "\n",
        "        for epoch in range(self.start_epoch, num_epochs):\n",
        "            # Train\n",
        "            train_loss = self.train_epoch(epoch + 1)\n",
        "\n",
        "            # Validate\n",
        "            val_dice = self.validate(epoch + 1)\n",
        "\n",
        "            # Scheduler step\n",
        "            self.scheduler.step(val_dice)\n",
        "\n",
        "            # Get current learning rate\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Log metrics\n",
        "            metrics = {\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': train_loss,\n",
        "                'val_dice': val_dice,\n",
        "                'learning_rate': current_lr,\n",
        "                'best_dice': self.best_dice\n",
        "            }\n",
        "\n",
        "            self.history.append(metrics)\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
        "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "            print(f\"  Val Dice: {val_dice:.4f}\")\n",
        "            print(f\"  LR: {current_lr:.6f}\")\n",
        "            print(f\"  Best Dice: {self.best_dice:.4f}\")\n",
        "\n",
        "            # Log to wandb\n",
        "            if self.use_wandb:\n",
        "                wandb.log(metrics)\n",
        "\n",
        "            # Check if best model\n",
        "            is_best = val_dice > self.best_dice\n",
        "            if is_best:\n",
        "                self.best_dice = val_dice\n",
        "\n",
        "            # Save checkpoint\n",
        "            self.save_checkpoint(epoch, val_dice, is_best)\n",
        "\n",
        "            # Save history CSV\n",
        "            self.save_history_csv()\n",
        "\n",
        "        print(f\"\\nTraining complete! Best Dice: {self.best_dice:.4f}\")\n",
        "\n",
        "        if self.use_wandb:\n",
        "            wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:52.233975Z",
          "iopub.execute_input": "2025-10-25T08:54:52.23432Z",
          "iopub.status.idle": "2025-10-25T08:54:52.259214Z",
          "shell.execute_reply.started": "2025-10-25T08:54:52.234292Z",
          "shell.execute_reply": "2025-10-25T08:54:52.258192Z"
        },
        "id": "E1A7MPFlNQnl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create trainer"
      ],
      "metadata": {
        "id": "Olw4w8I3NQno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = UNetTrainer(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    config=CONFIG,\n",
        "    device=device,\n",
        "    # checkpoint_dir='/kaggle/working'    # Load model checkpoint\n",
        "    checkpoint_dir=output_dir,\n",
        "    use_wandb=use_wandb\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:52.260113Z",
          "iopub.execute_input": "2025-10-25T08:54:52.260404Z",
          "iopub.status.idle": "2025-10-25T08:54:52.282002Z",
          "shell.execute_reply.started": "2025-10-25T08:54:52.260376Z",
          "shell.execute_reply": "2025-10-25T08:54:52.28114Z"
        },
        "id": "_LTO-PikNQno"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. Start training"
      ],
      "metadata": {
        "id": "JNo41ZvuNQnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean memory\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:52.282935Z",
          "iopub.execute_input": "2025-10-25T08:54:52.283244Z",
          "iopub.status.idle": "2025-10-25T08:54:52.888177Z",
          "shell.execute_reply.started": "2025-10-25T08:54:52.283217Z",
          "shell.execute_reply": "2025-10-25T08:54:52.886739Z"
        },
        "id": "mbMZ0l8jNQnp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "trainer.train(num_epochs=CONFIG['num_epochs'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T08:54:52.889183Z",
          "iopub.execute_input": "2025-10-25T08:54:52.889537Z"
        },
        "id": "A1URoOvYNQn6",
        "outputId": "1a27ba64-f3f7-4cee-ee40-0ce6c54d04c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.21.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20251025_085453-u1dfv01h</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/levuhoangtung/my-3D-Unet-segment-RSNA/runs/u1dfv01h' target=\"_blank\">unet3d_20251025_085453</a></strong> to <a href='https://wandb.ai/levuhoangtung/my-3D-Unet-segment-RSNA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/levuhoangtung/my-3D-Unet-segment-RSNA' target=\"_blank\">https://wandb.ai/levuhoangtung/my-3D-Unet-segment-RSNA</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/levuhoangtung/my-3D-Unet-segment-RSNA/runs/u1dfv01h' target=\"_blank\">https://wandb.ai/levuhoangtung/my-3D-Unet-segment-RSNA/runs/u1dfv01h</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Created new W&B run: u1dfv01h\n\nStarting training from epoch 0 to 20\nDevice: cpu\nModel parameters: 5.65M\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 1 [Train]:   5%|▍         | 8/164 [04:24<1:18:53, 30.34s/it, loss=0.9538]",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "hD0N2G_oNQn7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Load Best Model for Inference"
      ],
      "metadata": {
        "id": "K-bADW32NQn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_checkpoint = torch.load(trainer.best_model_path, map_location=device)\n",
        "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
        "print(f\"Best model loaded from epoch {best_checkpoint['epoch']} with Dice: {best_checkpoint['best_dice']:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "OOdvvSZ2NQn8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V. Evaluation & Visualization"
      ],
      "metadata": {
        "id": "7L9ScH-iNQn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationEvaluator:\n",
        "    def __init__(self, model, val_loader, device, num_classes=6):\n",
        "        self.model = model\n",
        "        self.val_loader = val_loader\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.class_names = ['Background', 'Liver', 'Spleen', 'Kidney_L', 'Kidney_R', 'Bowel']\n",
        "\n",
        "    def compute_metrics(self):\n",
        "        \"\"\"Compute comprehensive metrics\"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        metrics = {\n",
        "            'dice': [],\n",
        "            'iou': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'specificity': [],\n",
        "            'hausdorff': []\n",
        "        }\n",
        "\n",
        "        # Per-class metrics\n",
        "        class_metrics = {cls: {metric: [] for metric in metrics.keys()}\n",
        "                        for cls in range(1, self.num_classes)}  # Skip background\n",
        "\n",
        "        print(\"Computing metrics on validation set...\")\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.val_loader):\n",
        "                images = batch['image'].to(self.device)\n",
        "                labels = batch['seg'].to(self.device)\n",
        "\n",
        "                # Inference\n",
        "                outputs = sliding_window_inference(\n",
        "                    images, (96, 96, 96), 1, self.model, overlap=0.5\n",
        "                )\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                # Convert to numpy\n",
        "                pred_np = preds.cpu().numpy()\n",
        "                label_np = labels.cpu().numpy()\n",
        "\n",
        "                # Compute metrics per class\n",
        "                for cls in range(1, self.num_classes):\n",
        "                    pred_cls = (pred_np == cls).astype(np.float32)\n",
        "                    label_cls = (label_np == cls).astype(np.float32)\n",
        "\n",
        "                    # Skip if no ground truth for this class\n",
        "                    if label_cls.sum() == 0:\n",
        "                        continue\n",
        "\n",
        "                    # Dice\n",
        "                    intersection = (pred_cls * label_cls).sum()\n",
        "                    dice = (2 * intersection) / (pred_cls.sum() + label_cls.sum() + 1e-8)\n",
        "                    class_metrics[cls]['dice'].append(dice)\n",
        "\n",
        "                    # IoU\n",
        "                    union = pred_cls.sum() + label_cls.sum() - intersection\n",
        "                    iou = intersection / (union + 1e-8)\n",
        "                    class_metrics[cls]['iou'].append(iou)\n",
        "\n",
        "                    # Precision, Recall, Specificity\n",
        "                    tp = intersection\n",
        "                    fp = pred_cls.sum() - intersection\n",
        "                    fn = label_cls.sum() - i\n",
        "                    tersection\n",
        "                    tn = ((pred_cls == 0) & (label_cls == 0)).sum()\n",
        "\n",
        "                    precision = tp / (tp + fp + 1e-8)\n",
        "                    recall = tp / (tp + fn + 1e-8)\n",
        "                    specificity = tn / (tn + fp + 1e-8)\n",
        "\n",
        "                    class_metrics[cls]['precision'].append(precision)\n",
        "                    class_metrics[cls]['recall'].append(recall)\n",
        "                    class_metrics[cls]['specificity'].append(specificity)\n",
        "\n",
        "                    # Hausdorff Distance (sample a subset for speed)\n",
        "                    if intersection > 0:\n",
        "                        try:\n",
        "                            # Get surface points (simplified)\n",
        "                            pred_points = np.argwhere(pred_cls[0] > 0)\n",
        "                            label_points = np.argwhere(label_cls[0] > 0)\n",
        "\n",
        "                            # Sample points if too many\n",
        "                            if len(pred_points) > 1000:\n",
        "                                pred_points = pred_points[np.random.choice(len(pred_points), 1000, replace=False)]\n",
        "                            if len(label_points) > 1000:\n",
        "                                label_points = label_points[np.random.choice(len(label_points), 1000, replace=False)]\n",
        "\n",
        "                            hd = max(directed_hausdorff(pred_points, label_points)[0],\n",
        "                                   directed_hausdorff(label_points, pred_points)[0])\n",
        "                            class_metrics[cls]['hausdorff'].append(hd)\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "        # Aggregate metrics\n",
        "        results = {}\n",
        "        for cls in range(1, self.num_classes):\n",
        "            results[self.class_names[cls]] = {\n",
        "                metric: np.mean(values) if values else 0.0\n",
        "                for metric, values in class_metrics[cls].items()\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_metrics(self, results):\n",
        "        \"\"\"Plot metrics comparison\"\"\"\n",
        "        metrics_to_plot = ['dice', 'iou', 'precision', 'recall', 'specificity']\n",
        "\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, metric in enumerate(metrics_to_plot):\n",
        "            classes = list(results.keys())\n",
        "            values = [results[cls][metric] for cls in classes]\n",
        "\n",
        "            axes[idx].bar(classes, values, color='steelblue', alpha=0.8)\n",
        "            axes[idx].set_title(f'{metric.upper()}', fontsize=14, fontweight='bold')\n",
        "            axes[idx].set_ylabel('Score', fontsize=12)\n",
        "            axes[idx].set_ylim([0, 1])\n",
        "            axes[idx].grid(axis='y', alpha=0.3)\n",
        "            axes[idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "            # Add value labels\n",
        "            for i, v in enumerate(values):\n",
        "                axes[idx].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=10)\n",
        "\n",
        "        # Hausdorff Distance (separate scale)\n",
        "        classes = list(results.keys())\n",
        "        hd_values = [results[cls]['hausdorff'] for cls in classes]\n",
        "        axes[5].bar(classes, hd_values, color='coral', alpha=0.8)\n",
        "        axes[5].set_title('Hausdorff Distance (lower is better)', fontsize=14, fontweight='bold')\n",
        "        axes[5].set_ylabel('Distance (voxels)', fontsize=12)\n",
        "        axes[5].grid(axis='y', alpha=0.3)\n",
        "        axes[5].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        for i, v in enumerate(hd_values):\n",
        "            axes[5].text(i, v + max(hd_values)*0.02, f'{v:.2f}', ha='center', fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'metrics_comparison.png'), dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Metrics plot saved to {output_dir}/metrics_comparison.png\")\n",
        "\n",
        "    def visualize_predictions(self, num_samples=3):\n",
        "        \"\"\"Visualize overlay masks\"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # Color map for organs\n",
        "        colors = ['black', 'red', 'green', 'blue', 'yellow', 'purple']\n",
        "        cmap = ListedColormap(colors)\n",
        "\n",
        "        samples_shown = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                if samples_shown >= num_samples:\n",
        "                    break\n",
        "\n",
        "                images = batch['image'].to(self.device)\n",
        "                labels = batch['seg'].to(self.device)\n",
        "\n",
        "                outputs = sliding_window_inference(\n",
        "                    images, (96, 96, 96), 1, self.model, overlap=0.5\n",
        "                )\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                # Convert to numpy\n",
        "                img_np = images[0, 0].cpu().numpy()\n",
        "                pred_np = preds[0].cpu().numpy()\n",
        "                label_np = labels[0].cpu().numpy()\n",
        "\n",
        "                # Select middle slices\n",
        "                D, H, W = img_np.shape\n",
        "                slices_to_show = [D//4, D//2, 3*D//4]\n",
        "\n",
        "                fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "\n",
        "                for idx, slice_idx in enumerate(slices_to_show):\n",
        "                    # Original image\n",
        "                    axes[idx, 0].imshow(img_np[slice_idx], cmap='gray')\n",
        "                    axes[idx, 0].set_title(f'Slice {slice_idx}: CT Image', fontsize=12)\n",
        "                    axes[idx, 0].axis('off')\n",
        "\n",
        "                    # Ground truth\n",
        "                    axes[idx, 1].imshow(img_np[slice_idx], cmap='gray')\n",
        "                    axes[idx, 1].imshow(label_np[slice_idx], cmap=cmap, alpha=0.5, vmin=0, vmax=5)\n",
        "                    axes[idx, 1].set_title(f'Ground Truth', fontsize=12)\n",
        "                    axes[idx, 1].axis('off')\n",
        "\n",
        "                    # Prediction\n",
        "                    axes[idx, 2].imshow(img_np[slice_idx], cmap='gray')\n",
        "                    axes[idx, 2].imshow(pred_np[slice_idx], cmap=cmap, alpha=0.5, vmin=0, vmax=5)\n",
        "                    axes[idx, 2].set_title(f'Prediction', fontsize=12)\n",
        "                    axes[idx, 2].axis('off')\n",
        "\n",
        "                # Add legend\n",
        "                from matplotlib.patches import Patch\n",
        "                legend_elements = [Patch(facecolor=colors[i], label=self.class_names[i])\n",
        "                                 for i in range(1, len(colors))]\n",
        "                fig.legend(handles=legend_elements, loc='lower center', ncol=5, fontsize=11)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(output_dir, f'overlay_sample_{samples_shown+1}.png'),\n",
        "                           dpi=150, bbox_inches='tight')\n",
        "                plt.show()\n",
        "\n",
        "                samples_shown += 1\n",
        "\n",
        "        print(f\"Overlay visualizations saved to {output_dir}/overlay_sample_*.png\")\n",
        "\n",
        "    def plot_3d_visualization(self, sample_idx=0):\n",
        "        \"\"\"3D visualization of segmentation\"\"\"\n",
        "        from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, batch in enumerate(self.val_loader):\n",
        "                if idx != sample_idx:\n",
        "                    continue\n",
        "\n",
        "                images = batch['image'].to(self.device)\n",
        "                labels = batch['seg'].to(self.device)\n",
        "\n",
        "                outputs = sliding_window_inference(\n",
        "                    images, (96, 96, 96), 1, self.model, overlap=0.5\n",
        "                )\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                pred_np = preds[0].cpu().numpy()\n",
        "                label_np = labels[0].cpu().numpy()\n",
        "\n",
        "                # Create 3D visualization for each organ\n",
        "                fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "                for organ_idx in range(1, min(4, self.num_classes)):  # Show first 3 organs\n",
        "                    # Ground truth\n",
        "                    ax1 = fig.add_subplot(2, 3, organ_idx, projection='3d')\n",
        "                    mask_gt = (label_np == organ_idx)\n",
        "                    if mask_gt.sum() > 0:\n",
        "                        z, y, x = np.where(mask_gt)\n",
        "                        ax1.scatter(x[::10], y[::10], z[::10], c='red', marker='o',\n",
        "                                  s=1, alpha=0.3)\n",
        "                    ax1.set_title(f'{self.class_names[organ_idx]} - Ground Truth', fontsize=12)\n",
        "                    ax1.set_xlabel('X')\n",
        "                    ax1.set_ylabel('Y')\n",
        "                    ax1.set_zlabel('Z')\n",
        "\n",
        "                    # Prediction\n",
        "                    ax2 = fig.add_subplot(2, 3, organ_idx + 3, projection='3d')\n",
        "                    mask_pred = (pred_np == organ_idx)\n",
        "                    if mask_pred.sum() > 0:\n",
        "                        z, y, x = np.where(mask_pred)\n",
        "                        ax2.scatter(x[::10], y[::10], z[::10], c='blue', marker='o',\n",
        "                                  s=1, alpha=0.3)\n",
        "                    ax2.set_title(f'{self.class_names[organ_idx]} - Prediction', fontsize=12)\n",
        "                    ax2.set_xlabel('X')\n",
        "                    ax2.set_ylabel('Y')\n",
        "                    ax2.set_zlabel('Z')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(output_dir, '3d_visualization.png'),\n",
        "                           dpi=150, bbox_inches='tight')\n",
        "                plt.show()\n",
        "\n",
        "                print(f\"3D visualization saved to {output_dir}/3d_visualization.png\")\n",
        "                break\n",
        "\n",
        "    def create_summary_report(self, results):\n",
        "        \"\"\"Create text summary report\"\"\"\n",
        "        report_path = os.path.join(output_dir, 'evaluation_report.txt')\n",
        "\n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(\"=\"*60 + \"\\n\")\n",
        "            f.write(\"SEGMENTATION EVALUATION REPORT\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "            for cls_name, metrics in results.items():\n",
        "                f.write(f\"\\n{cls_name}:\\n\")\n",
        "                f.write(\"-\" * 40 + \"\\n\")\n",
        "                f.write(f\"  Dice Coefficient:  {metrics['dice']:.4f}\\n\")\n",
        "                f.write(f\"  IoU:              {metrics['iou']:.4f}\\n\")\n",
        "                f.write(f\"  Precision:        {metrics['precision']:.4f}\\n\")\n",
        "                f.write(f\"  Recall:           {metrics['recall']:.4f}\\n\")\n",
        "                f.write(f\"  Specificity:      {metrics['specificity']:.4f}\\n\")\n",
        "                f.write(f\"  Hausdorff Dist:   {metrics['hausdorff']:.2f} voxels\\n\")\n",
        "\n",
        "            # Overall average (excluding background)\n",
        "            f.write(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "            f.write(\"OVERALL AVERAGES:\\n\")\n",
        "            f.write(\"-\"*60 + \"\\n\")\n",
        "\n",
        "            for metric in ['dice', 'iou', 'precision', 'recall', 'specificity']:\n",
        "                avg = np.mean([results[cls][metric] for cls in results.keys()])\n",
        "                f.write(f\"  Average {metric.upper()}: {avg:.4f}\\n\")\n",
        "\n",
        "        print(f\"\\nEvaluation report saved to {report_path}\")\n",
        "\n",
        "        # Print to console\n",
        "        with open(report_path, 'r') as f:\n",
        "            print(f.read())"
      ],
      "metadata": {
        "trusted": true,
        "id": "tKM0WtBzNQn9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = SegmentationEvaluator(model, val_loader, device, num_classes=CONFIG['num_classes'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "bMM3EpIrNQoB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Compute all metrics"
      ],
      "metadata": {
        "id": "nXbTSCB0NQoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Computing metrics\")\n",
        "results = evaluator.compute_metrics()"
      ],
      "metadata": {
        "trusted": true,
        "id": "0cVtJtJoNQoC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Plot metrics comparison"
      ],
      "metadata": {
        "id": "FNPCZC4HNQoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Plotting metrics comparison\")\n",
        "evaluator.plot_metrics(results)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2v5VpvzjNQoD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Visualize overlay masks"
      ],
      "metadata": {
        "id": "D1jlWCj2NQoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating overlay visualizations\")\n",
        "evaluator.visualize_predictions(num_samples=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7XzuFe83NQoE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 3D visualization"
      ],
      "metadata": {
        "id": "s_Xd82l-NQoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.plot_3d_visualization(sample_idx=0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZJaAmGqWNQoG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "JLpEoNf7NQoH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Create summary report"
      ],
      "metadata": {
        "id": "Nx9vnkhxNQoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.create_summary_report(results)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YsjA-7fANQoI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "oTkaheh7NQoI"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}